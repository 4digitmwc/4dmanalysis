{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression for Qualifiers against Team Survival\n",
    "\n",
    "### Objectives\n",
    "Qualifiers could arguably be similar to a dan; of course, the choice of patterning and difficulty are well balanced and executed in the mapping of these charts, but ultimately, it is akin to playing 4-8 maps and seeing who's better at them. \n",
    "Beyond seeding, they may not even matter. Or at least, the relationship between good performances in the qualifier vs bracket stage is not well established.\n",
    "\n",
    "Is it then fair to determine that a 4 digit player is overskilled, because of their performance in the qualifiers? This is the question we attempt to answer today.\n",
    "- Have the qualifiers, as promised by qualifier mappers and poolers, been able to decently represent the performance of teams across different rounds?\n",
    "- How does a team's performance in a specific qualifier map affect their chances of advancing to each of the rounds?\n",
    "\n",
    "In order to answer these questions, we will be extracting the qualifier scores from all teams and their last round of participation, and run a *logistic regression* model over them.\n",
    "\n",
    "### What is Logistic Regression?\n",
    "*Logistic Regression* is a statistical method that models the probability of an event taking place, given other independent variables of the observation. This is done by having the *logarithmic* odds of an event happening be mathematically modelled after the independent variables of the observation. \n",
    "\n",
    "In this exploratory data analysis, we note that a model has yet to be established; hence, we will be **estimating the parameters of the logistic model** relating each team's qualifier scores to their odds of survival in each round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages\n",
    "\n",
    "For this data analysis, a couple of libraries and modules are used:\n",
    "- Standard libraries such as NumPy, Pandas, Matplotlib are needed for pretty much any form of data visualization!\n",
    "- The Logistic Regression model from sklearn, and its evaluative metric package are also imported.\n",
    "- the *get_table* function is also imported for an efficient way to handle the tables obtained from the dataset;\n",
    "- the datasets are imported from the Dataset class, a class created by HowToPlayLN (HowToProgramming) for all data analysis projects performed using 4DM4 data. See the documentation for the Dataset class [here](https://github.com/HowToProgramming/4dm4analysis/blob/main/readme.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from utils import Dataset\n",
    "from utils import get_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Dataset \n",
    "Making use of the Dataset class provided, we will be able to grab all team scores for 4DM4. This is done so by restricting the query to the \"team_scores\" table. The query is restricted to purely qualifier scores. This will allow each team's combined score on each of the Qualifier stages (excluding SV) to be used as an independent variable that adds to the log-odds of the team clearing a specific round.\n",
    "\n",
    "We will also be able to extract the dependent variable, which is the last round of participation for every team involved in 4DM4. This is done by accessing the \"team_data\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_4dm4 = Dataset(\"datasets/4dm3.db\")\n",
    "\n",
    "def qual_database(lst):\n",
    "    res = pd.DataFrame()\n",
    "    for type in lst:\n",
    "        ds = _4dm4.select(table=\"team_scores\", \n",
    "                            columns=[\"country_name\", \"round\", \"beatmap_type\", \"beatmap_tag\", \"score\", \"score_logit\"],\n",
    "                            where={\n",
    "                                \"round\": \"\\\"Q\\\"\",\n",
    "                                \"beatmap_type\": f\"\\\"{type}\\\"\"\n",
    "                            }\n",
    "                        )\n",
    "        res = pd.concat([res, ds])\n",
    "    return res\n",
    "\n",
    "interested_types = [\"RC\", \"LN\", \"HB\"]\n",
    "qual_data = qual_database(interested_types)\n",
    "\n",
    "team_finalrd = _4dm4.select(table=\"team_data\",\n",
    "                            columns=[\"country_name\", \"country_code\", \"last_rdint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>round</th>\n",
       "      <th>beatmap_type</th>\n",
       "      <th>beatmap_tag</th>\n",
       "      <th>score</th>\n",
       "      <th>score_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Q</td>\n",
       "      <td>RC</td>\n",
       "      <td>1</td>\n",
       "      <td>2975973</td>\n",
       "      <td>4.819148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Q</td>\n",
       "      <td>RC</td>\n",
       "      <td>1</td>\n",
       "      <td>2980836</td>\n",
       "      <td>5.046926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>Q</td>\n",
       "      <td>RC</td>\n",
       "      <td>1</td>\n",
       "      <td>2983513</td>\n",
       "      <td>5.198285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Q</td>\n",
       "      <td>RC</td>\n",
       "      <td>1</td>\n",
       "      <td>2993464</td>\n",
       "      <td>6.126861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Q</td>\n",
       "      <td>RC</td>\n",
       "      <td>1</td>\n",
       "      <td>2981094</td>\n",
       "      <td>5.060566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>Q</td>\n",
       "      <td>HB</td>\n",
       "      <td>1</td>\n",
       "      <td>2938037</td>\n",
       "      <td>3.858960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Q</td>\n",
       "      <td>HB</td>\n",
       "      <td>1</td>\n",
       "      <td>2864382</td>\n",
       "      <td>3.050266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Taiwan, Province of China</td>\n",
       "      <td>Q</td>\n",
       "      <td>HB</td>\n",
       "      <td>1</td>\n",
       "      <td>2921759</td>\n",
       "      <td>3.620147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>United States</td>\n",
       "      <td>Q</td>\n",
       "      <td>HB</td>\n",
       "      <td>1</td>\n",
       "      <td>2947731</td>\n",
       "      <td>4.032388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Q</td>\n",
       "      <td>HB</td>\n",
       "      <td>1</td>\n",
       "      <td>2890058</td>\n",
       "      <td>3.269079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country_name round beatmap_type beatmap_tag    score  \\\n",
       "0                   Argentina     Q           RC           1  2975973   \n",
       "1                   Australia     Q           RC           1  2980836   \n",
       "2                     Belgium     Q           RC           1  2983513   \n",
       "3                      Brazil     Q           RC           1  2993464   \n",
       "4                      Canada     Q           RC           1  2981094   \n",
       "..                        ...   ...          ...         ...      ...   \n",
       "29                   Thailand     Q           HB           1  2938037   \n",
       "30                     Turkey     Q           HB           1  2864382   \n",
       "31  Taiwan, Province of China     Q           HB           1  2921759   \n",
       "32              United States     Q           HB           1  2947731   \n",
       "33                   Viet Nam     Q           HB           1  2890058   \n",
       "\n",
       "    score_logit  \n",
       "0      4.819148  \n",
       "1      5.046926  \n",
       "2      5.198285  \n",
       "3      6.126861  \n",
       "4      5.060566  \n",
       "..          ...  \n",
       "29     3.858960  \n",
       "30     3.050266  \n",
       "31     3.620147  \n",
       "32     4.032388  \n",
       "33     3.269079  \n",
       "\n",
       "[102 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Transformation\n",
    "Currently, a single country's score on a single stage is populated on each row. However, this is not the format required to fit in the model - We will need the scores for each stage to be populated in a single row, for each country. This is where the 'get_table' function from the inbuilt 'utils' module comes into play; it provides a quick and easy way for us to present the data in this required format for the logistic regression model.\n",
    "\n",
    "Furthermore, an integer label was introduced to every team that made it past RO16; this is to counter the lack of a timestamp or any form of unbiased X-axis that could possibly represent the scaling of difficulty over each of the rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_finalrd.index = team_finalrd[\"country_name\"]\n",
    "qual_scores_table = get_table(qual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Q_RC_1    Q_LN_1    Q_HB_1\n",
      "Argentina           4.819148  3.000425  3.576483\n",
      "Australia           5.046926  3.116724  3.670724\n",
      "Belgium             5.198285  3.405876  3.731808\n",
      "Brazil              6.126861  4.415284  4.713861\n",
      "Canada              5.060566  2.859818  3.384376\n",
      "Switzerland         4.239259  2.493175  2.863859\n",
      "China               5.448966  3.318993  3.629824\n",
      "Germany             5.287426  3.198382  3.615342\n",
      "Dominican Republic  4.711442  3.073595  3.143412\n",
      "Spain               4.795019  2.670776  3.289168\n"
     ]
    }
   ],
   "source": [
    "print(qual_scores_table.head(n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          country_name country_code  last_rdint\n",
      "country_name                                                   \n",
      "Argentina                    Argentina           AR           1\n",
      "Australia                    Australia           AU           1\n",
      "Belgium                        Belgium           BE           3\n",
      "Brazil                          Brazil           BR           6\n",
      "Canada                          Canada           CA           1\n",
      "Switzerland                Switzerland           CH           1\n",
      "China                            China           CN           2\n",
      "Germany                        Germany           DE           3\n",
      "Dominican Republic  Dominican Republic           DO           1\n",
      "Spain                            Spain           ES           1\n"
     ]
    }
   ],
   "source": [
    "print(team_finalrd.head(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Solvers for Logistic Regression:\n",
    "With all the data prepared, we can finally proceed with the data analysis. As the super uneducated student as I (Poly) am, I will first experiment with everything we can get our hands dirty with.\n",
    "\n",
    "So you might question, what is a *solver*?\n",
    "\n",
    "To put it simply, *solvers* are tools we use in logistic regression. These *solvers* use a variety of methods to solve for the coefficients with the least error in predicting whether an event happens in all observations; Loosely speaking, we will attempt to find a *solver* among the 6 introduced below that provides the highest accuracy in predicting whether each team survives the round in question, and obtain the coefficients attached to each of the team's scores. These coefficients give us an idea of whether the stage in question significantly affects the chances of a team surviving beyond a round. The higher this coefficient is, the more effect the stage has on a team surviving the specific round! \n",
    "\n",
    "Now we shall look into each of the 6 solvers. They will be covered in as little detail as required to understand the differences between the performance of each model, and a more specific explanation can be found [here](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions#:~:text=It's%20a%20linear%20classification%20that,coordinate%20directions%20or%20coordinate%20hyperplanes.).\n",
    "\n",
    "#### L1/L2 Stochastic Average Gradient (SAG), and its Alternate Model (SAGA)\n",
    "For these 3 models, the Stochastic Average Gradient (SAG) model is used. Like other Stochastic Gradient Descent (SGD) methods, this solver implements an iterative method to solve for the parameters of the model by \"smoothening\" fluctuations in data points through approximation. Additionally, it also allocates some memory to remember the previous gradient values approximated by the model, so it spends much lesser time calculating and converging to the final solution. This solver is more effective for logistic regression involving a few (sparse) dependent variables, and across a larger dataset.\n",
    "\n",
    "- It is also to be noted that our dataset for 4DM4 is rather small; this model may in fact not be as effective.\n",
    "\n",
    "The SAG model also has a variant SAGA, which supports a non-smooth penalty L1 term alongside L2. Both L1 and L2 penalty terms are used to tune and refine a function such that the final coefficients consider extreme values to a much lower extent, increasing its accuracy in predicting the correct parameters. \n",
    "\n",
    "In which case, both L1 and L2 penalty terms are attempted because I suck lol.\n",
    "\n",
    "#### L2 Newton\n",
    "Newton's Method, on the other hand, solves for the parameters by taking steps closer to the final parameters, through a method that allows the model to be approximated as a quadratic equation. This makes use of both the first and second partial derivatives, utilising the Hessian matrix. This process repeats until the minimum/maximum point is achieved, and parameters are determined.\n",
    "\n",
    "This method requires more computing power due to the implementation of the Hessian Matrix in its solver. \n",
    "\n",
    "#### L2 Limited-memory Broyden-FLetcher-Goldfarb-Shanno (L-BFGS)\n",
    "The L-BFGS model could be said to be a rehash of the Newton Method. However, the model reverses the computations made by the Hessian Matrix, by using an inverse of itself.\n",
    "\n",
    "- It is to be noted that this model will not work if the Hessian Matrix is singular (i.e. not invertible).\n",
    "\n",
    "- This model is however predicted to have the best performance compared to other methods, as it saves up lots of memory on smaller datasets. For our application, this could be the best use case.\n",
    "\n",
    "#### L2 Large Linear Classification\n",
    "This Linear Classification model applies L1 Regularization techniques along with linear support vector machines, allowing the solver to work on datasets with higher dimensions (i.e. datasets with more than 3 variables. The more, the better it performs relative to other models.)\n",
    "\n",
    "- This generally does not run efficiently with the relatively small amount of data obtained for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Models\n",
    "The models as introduced, will be implemented into the code now.\n",
    "\n",
    "Furthermore, the hyperparameter C is introduced to the model; This *C hyperparameter* adds a penalty for each misclassified data point.\n",
    "- If C is larger, the penalty is low so a decision with a large margin for error is introduced at the expense of misclassification. In other words, the model is more forgiving towards misclassifications, but also tends to run foul. A larger C parameter would be more relevant for futureproof models, and could possibly work better if we end up having to deal with scores from participants that we have never seen in the context of a tournament like 4DM.\n",
    "\n",
    "- If C is smaller, the model is stricter, and classifies better. However, it also runs the risk of 'overtuning' itself to the data already introduced, and may not know how to react when faced with new data that causes breaks in the boundaries of the model's logic. \n",
    "\n",
    "In this iteration of the analysis, the C hyperparameter is set to a relatively high penalty value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of models for logistic regression;\n",
    "C = 10\n",
    "classifiers = {\n",
    "    \"L1 logistic\": LogisticRegression(\n",
    "        C=C, penalty=\"l1\", solver=\"saga\", multi_class=\"ovr\", max_iter=10000\n",
    "    ),\n",
    "    \"L2 logistic (OvR)\": LogisticRegression(\n",
    "        C=C, penalty=\"l2\", solver=\"saga\", multi_class=\"ovr\", max_iter=10000\n",
    "    ),\n",
    "    \"L2 L-BFGS\": LogisticRegression(\n",
    "        C=C, penalty=\"l2\", solver=\"lbfgs\", multi_class=\"ovr\", max_iter=10000\n",
    "    ),\n",
    "    \"L2 Newton\": LogisticRegression(\n",
    "        C=C, penalty=\"l2\", solver=\"newton-cg\", multi_class=\"ovr\", max_iter=10000\n",
    "    ),\n",
    "    \"L2 Large Linear Classification\": LogisticRegression(\n",
    "        C=C, penalty=\"l2\", solver=\"liblinear\", multi_class=\"ovr\", max_iter=10000\n",
    "    ),\n",
    "    \"L2 Stochastic Average Gradient\": LogisticRegression(\n",
    "        C=C, penalty=\"l2\", solver=\"sag\", multi_class=\"ovr\", max_iter=10000\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The previously prepared data will now be fit into each of the 6 models.\n",
    "\n",
    "A couple of functions were implemented to better facilitate the analysis of the model parameters for each round:\n",
    "- \"rd_regression\": This takes a round and its corresponding integer. This integer is compared to the last_round integer for each of the teams, and if both integers are the same, the team is declared dead after the round has concluded. \n",
    "\n",
    "- A column \"alive_afterrd\" is also introduced to the data, which will show whether the team survived the round in question (0 for no, and 1 for yes). In which case, if both round integers are the same, a team will be marked a 0, and if the team's last round int is greater, then they are marked a 1. This forms the independent variable the model is supposed to predict.\n",
    "\n",
    "- for each classifier in the 6 classifier models, the data is fit into the classifier, and the model parameters are yielded and saved into a dataframe for easier viewing and visualization later on.\n",
    "\n",
    "- The codeline that prints the Coefficient Matrix (a comparison between correct/incorrect Positive and Negative classifications) obtained by running the obtained model across the same data used to train the model (due to very limited size of data obtained) is also included but not run; feel free to uncomment and print this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable warnings that will fill up the output\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#fit qualiiers scores for each team as X, whether they survived in round (binary 0/1) as Y\n",
    "def rd_regression(round):\n",
    "    team_alive = team_finalrd[team_finalrd[\"last_rdint\"] >= interested_rds[round]-1] #include all teams who advanced to the current round in iteration\n",
    "    qual_scores_team = qual_scores_table[qual_scores_table.index.isin(team_alive[\"country_name\"].unique().tolist())]\n",
    "    team_alive[\"alive_afterrd\"] = team_alive.last_rdint.apply(lambda x: 0 if int(x) == interested_rds[round] else 1)\n",
    "    team_alive.loc[team_alive[\"country_name\"] == \"Philippines\", \"alive_afterrd\"] = 1 #France is technically the only country to advance from GF as the winner of the tournament\n",
    "    X, y = qual_scores_team, team_alive[\"alive_afterrd\"].ravel()\n",
    "    X_train, X_test, y_train, y_test = X, X, y, y\n",
    "    \n",
    "    #generate table with all exponentiated coefficients for each independent variable i.e. each stage\n",
    "    fin = pd.DataFrame(columns = [\"Round\", \"Classifier\", \"Q_RC1\", \"Q_LN1\", \"Q_HB1\", \"Intercept\"])\n",
    "    for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "        res = pd.DataFrame(columns = [\"Round\", \"Classifier\", \"Q_RC1\", \"Q_LN1\", \"Q_HB1\", \"Intercept\"])\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "        #print(f\"Confusion Matrix: \\n{cnf_matrix}\")\n",
    "        coefs_arr = np.exp(classifier.coef_).flatten().tolist()\n",
    "        coefs_arr.insert(0, name)\n",
    "        coefs_arr.insert(0, round)\n",
    "        coefs_arr.append(classifier.intercept_[0])\n",
    "        res.loc[len(res)] = coefs_arr\n",
    "        fin = pd.concat([fin, res], axis = 0, ignore_index = True)\n",
    "    fin.index.rename(f'{round}', inplace=True)\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis II\n",
    "From here, we make use of the 'rd_regression' model to obtain a table including the parameters and intercept of the final model with the least error in predicting the survival rate of each team in 4DM based off their qualifier scores. This is looped through for every round.\n",
    "\n",
    "The results are available for each of the 6 models included in the analysis; however, after checking their evaluative metrics (making use of the [Coefficient Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)), both the Newton and L-BFGS solvers better predicted the survival rates of teams across each of the bracket rounds (starting from RO16 as no countries were eliminated before that).\n",
    "\n",
    "After a discussion with HowToPLayLN, we decided that the Newton model would be more robust in terms of calculation, thus considering the small number of data points in this dataset we decided to have the Newton solver's results be used for the final data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_rds = {\"GS\": 1, \"QF\": 3, \"SF\": 4, \"F\": 5, \"GF\": 6}    \n",
    "result = pd.DataFrame(columns = [\"Round\", \"Classifier\", \"Q_RC1\", \"Q_LN1\", \"Q_HB1\", \"Intercept\"])\n",
    "for rd in interested_rds:\n",
    "    models_rd = rd_regression(rd)\n",
    "    result = pd.concat([result, models_rd], axis = 0, ignore_index = True)\n",
    "\n",
    "newton = result[result[\"Classifier\"] == \"L2 Newton\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "The parameters for each of the stages relative to each round is plotted on a line graph:\n",
    "- Q_RC1 stands for [Antihero [Stage 2: Defiance]](https://osu.ppy.sh/beatmapsets/1665428#mania/3399967),\n",
    "- Q_RC2 stands for [Fury [Stage 4: Conflagration]](https://osu.ppy.sh/beatmapsets/1665436#mania/3399979),\n",
    "- Q_LN1 stands for [Transform (Original Mix) [Stage 3: Homeomorphism]](https://osu.ppy.sh/beatmapsets/1665269#mania/3399628),\n",
    "- Q_HB1 stands for [HIVEMIND [Stage 5: Controlled Chaos]](https://osu.ppy.sh/beatmapsets/1665442#mania/3399992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Round Classifier     Q_RC1      Q_LN1     Q_HB1  Intercept\n",
      "3       1  L2 Newton  2.193943   1.475144  4.581896 -10.417435\n",
      "9       3  L2 Newton  2.494569  18.870479  1.368126 -14.677905\n",
      "15      4  L2 Newton  0.622720   1.848488  1.998744  -1.963261\n",
      "21      5  L2 Newton  1.655804   0.115672  0.367432  10.757683\n",
      "27      6  L2 Newton  0.451930   1.718874  0.767957   4.017446\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABC3UlEQVR4nO3deXxU9dX48c/JRkI2IASSEHaQJUEQIsimuANVgTx28bF9ajdr1af1aW3t9qt2sa1drLZarXVv7WqLO6DFDcImCMi+gwQICVt2ss35/XEnIYmTZJLM5M4k5/163dfM3Llz7xmWe+a7i6pijDHGNBfhdgDGGGNCkyUIY4wxPlmCMMYY45MlCGOMMT5ZgjDGGONTlNsBBFL//v112LBhbodhjDFhY8OGDSdUNdXXe90qQQwbNoz169e7HYYxxoQNETnU0ntWxWSMMcYnSxDGGGN8sgRhjDHGp27VBuFLTU0N+fn5nD171u1QQkJsbCyZmZlER0e7HYoxJsR1+wSRn59PYmIiw4YNQ0TcDsdVqsrJkyfJz89n+PDhbodjjAlx3b6K6ezZs6SkpPT45AAgIqSkpFhpyhjjl26fIABLDo3Yn4Uxxl89IkEYQ81ZeO9xqK5wOxJjwka3b4MwBoC3fwp5D4IqTP2S29EYExasBNEF8vPzWbBgAaNHj2bEiBHcfvvtVFVV+Tz27bffJjk5mUmTJjF27FjuvPPOhvfKysr48pe/zMiRI5kyZQpz5sxh7dq1AHz+859nwIABZGdnd8l3Civ562HV75znW//tbizGhBFLEEGmquTm5rJw4UL27NnDnj17qKys5Fvf+laLn5k9ezabNm1i48aNvPLKK+Tl5QHwxS9+kX79+rFnzx42bNjAU089xYkTJwC46aabWLp0aZd8p7BScxZeuBUS02H67fDhaig56nZUxoSFHlXF9MOXt7H9aElAzzk+I4m7r81q8f0333yT2NhYPve5zwEQGRnJb37zG4YOHcq9995LQkJCi5+Ni4tj0qRJHDlyhH379rF27Vqee+45IiKcvD58+PCG7qoXX3wxBw8eDNwX6y7e+Tmc2AU3/gv6DoXVD8G2F2D6rW5HZkzIsxJEkG3bto0pU6Y02ZeUlMSwYcPYu3dvq589ffo0e/bs4eKLL2bbtm1MmjSJyMjIYIbbvRzZ4LQ7XPBpGH0F9B8NAyfAtsVuR2ZMWOhRJYjWfumHkhUrVjBx4kT27NnDHXfcQVpamtshhZ/aKqdqKSENrrr33P7sRbD8R3DmMPQZ7F58xoQBK0EE2fjx49mwYUOTfSUlJRQUFDBmzBifn5k9ezabN29m27ZtPPHEE2zatImsrCw2b95MXV1dV4Qd/t65D4p2wrUPQlyfc/uzcp1HK0UY0yZLEEF2+eWXU1FRwbPPPgtAXV0d3/jGN7j99tuJi4tr9bPDhw/n29/+Nvfddx8jR44kJyeHu+++G1UF4ODBg7z66qtB/w5h58j7sPIBmHQjnHdV0/f6DYeMC2Cb9WYypi2WIIJMRFi8eDHPP/88o0ePJiUlhYiICL73ve/59flbbrmFd999l4MHD/L4449z/PhxRo0aRXZ2NjfddBMDBgwA4IYbbmD69Ons2rWLzMxMnnjiiWB+rdBVWwUv3gYJA+Dqe30fk5ULRzfCqf1dG5sxYUbqf412Bzk5Odp8RbkdO3Ywbtw4lyL6qFWrVnHDDTewePFiJk+e7EoMofZnElBv/gTe/SX89z/gvKt9H3PmQ3hgAlz+A5j9ja6Nz5gQIyIbVDXH13tWguhiM2bM4NChQ64lh27t6CZYcT9MvKHl5ADQZwhkXghbrR3CmNZYgnDJsmXLmDRpUpNt0aJFbocVvmqrnV5L8akw92dtH5+VC8e3wIk9wY/NmDAVtG6uIvIkcA1QqKrZ3n1/B+q77vQBzqjqJB+fPQiUAnVAbUvFn3B29dVXc/XVrfzKNe2z4ldQuA1u+BvE9W37+KyFsOy7Tm+mS1oe1W5MTxbMEsTTwNzGO1T1k6o6yZsU/gW01pXkUu+x3S45mAA7thlW/BrO/ySMmeffZ5IyYMh0m5vJmFYELUGo6rvAKV/vibMowSeAvwbr+qaHqK2GF26DuH4w9+ft+2x2LhTtgMIdwYnNmDDnVhvEbOC4qrZUAazA6yKyQURubu1EInKziKwXkfVFRUUBD9SEuJX3O20J1z4Avfu177PjF4BEWCnCmBa4lSBuoPXSwyxVnQzMA24TkYtbOlBVH1PVHFXNSU1NDXScJpQVbHG6tE74OIz9WPs/nzAAhs1yBs11o+7exgRKlycIEYkCcoG/t3SMqh7xPhYCi4GpXRNdcLR3PYhrrrnmI/vnzJlDTs655pj169czZ84cAE6ePMmll15KQkICt99+e1C+Q8ipq4EXvuI0SM/7RcfPk7UITu51ko0xpgk3ShBXADtVNd/XmyISLyKJ9c+Bq4CtXRhfQHVkPYiWFBYWsmTJko/sj42N5cc//jG/+tWvAhFyeFj5G+emfs1v2l+11Ni4BSCRNjeTMT4Es5vrX4E5QH8RyQfuVtUngE/RrHpJRDKAx1V1PjAQWOy0YxMF/EVVA7MSzpJvB/6XYtoEmNdy42hn1oNo7pvf/Cb33nsv8+Y17akTHx/PrFmz2pw+vNso2Arv/AKy/wvGXdu5c8WnwIhLnGqmy38Azr87YwzB7cV0g6qmq2q0qmZ6kwOqepOqPtrs2KPe5ICq7lfVid4tS1VbmFAnPHRmPYjmpk+fTkxMDG+99VYgQwwvdTXw4q0QmwzzfhmYc2blwumDzvxMxpgGPWo9iNZ+6YeL73//+/zkJz/hvvvuczsUd+Q94Ix7+MSzzq//QBh3Dbzyf04pYpBNgWJMPZtqI8g6sh5Eay677DIqKytZs2ZNoEIMH8e3w9v3OQ3L4xcE7rxxfWHkZc5SpNabyZgGliCCrDPrQbTk+9//Pr/4RSd67oSjulqn11JsEswPQmN8di4UH4b89wJ/bmPClCWIIOvIehDLly8nMzOzYVu9enWT9+fPn0/zMR/Dhg3j61//Ok8//TSZmZls3749KN/HNat+C8c2wcd+DfH9A3/+MfMgMsYGzRnTSM9qg3DJ4MGDeemll4Bz60G8//77Pqf8njNnDpWVlR/Z//bbbzd53bza6uDBgwGLN+QU7oS3f+ZUK2UFacbb2GQYdSVsfwGu/ilE2G8nY+x/QRez9SDaqa7W6bUUkwDzfx3ca2XnQukxONwD23eM8cFKEC5ZtmwZd911V5N9w4cPZ/FiG7DVxOqH4MgGuP5JSAjyVCrnzYWoOKeaaeiM4F7LmDBgCcIlth6EH4p2wVs/dQbDZeUG/3q9EuC8q2D7izDvPoiIDP41jQlhVsVkQpOnzlkhLqY3fOz+rhvhnJUL5YVwcGXXXM+YEGYJwoSm1Q/DkfVOl9aEAV133dFXQXS8M2jOmB7OEoQJPUW74c2fwNhrnPmWulJMbxgzF7a/5EzrYUwPZgnChBZPHbx4G0THdW3VUmNZuVB5Cg682/XXNiaEtCtBiEhfETk/WMF0V51dD+Kmm27i+eefB5xxEmPGjGHSpEmMGzeOxx57rOG4733vewwePLhdM8SGnDWPQP46mP9LSBzoTgyjroBeSVbNZHq8NhOEiLwtIkki0g94H/ijiNwf/NC6h0CuB1HvueeeY9OmTeTl5XHXXXdRXV0NwLXXXsu6desCFXrXO7EX3vwxjJnvrBLnluhYJ4YdLztrXhvTQ/nTzTVZVUtE5IvAs6p6t4h8EOzAguG+dfex89TOgJ5zbL+x3DX1rhbfD+R6EM2VlZURHx9PZKTTHfOiiy7q8LlcV1+1FNXLWQTI7XUZsnPhg7/B/rfgPOuObHomfxJElIikA58AWp5AyPjU1noQkyZN+shnVqxY0WT/hx9+2KTa6cYbb6RXr17s2bOHBx54oCFBhLW1f3BGMC/6AySmuR0NjLgUYvs4g+YsQZgeyp8E8UNgGbBSVd8TkRHAnuCGFRyt/dIPJbNnz+aVV15peH3TTTc1ef+5554jJyeHoqIiZsyYwdy5cxk6dGgXRxlAJ/fB8h85I5nP/6Tb0TiiYpx1Ira9CDVnnWonY3oYfxqpj6nq+ap6KzgrvgFttkGIyJMiUigiWxvtu0dEjojIJu82v4XPzhWRXSKyV0S+7e+XCUWBXg+isdTUVCZPnszatWs7dR5XeTzeqqUYuOYB96uWGstaBNWlsPc/bkdijCv8SRC/83Nfc08Dc33s/42qTvJurzV/U0QigYeBecB44AYRGe/H9UJSMNaDqFdRUcHGjRsZOXJkIEJ1x7rH4MPVMPfnkJTudjRNDb8E4vrBNpsfy/RMLSYIEZkuIt8AUkXk6422e4A2K71V9V3gVAdimgrs9a5NXQ38DQjg8mFdqyPrQbTlxhtvZNKkSUyZMoWbbrqpoY3jW9/6FpmZmVRUVJCZmck999wToG8RJCf3wX/ucUYvT7zB7Wg+KjIaxl8Hu5ZAdYXb0RjT5URbWGJRRC4B5gC3AI82eqsUeFlV22yHEJFhwCuqmu19fQ9wE1ACrAe+oaqnm33memCuqn7R+/ozwDRVvb2Fa9wM3AwwZMiQKYcOHWry/o4dOxg3blxboXaZ+vUgFi9e7NqU3yHxZ+LxwDPXQMFWuG0NJGW4G09L9r8Dz14HH38Gsha6HY0xASciG1Q1x9d7LTZSq+o7wDsi8rSqHmrpuHZ6BPgxoN7HXwOf78wJVfUx4DGAnJyckF9QuH49iB7vvcfhUB4seDh0kwPAsFkQP8AZNGcJwvQw/vRi6iUijwHDGh+vqpe192Kqerz+uYj8EXjFx2FHgMGNXmd693UrPXo9iFMH4D93OyOWJ93odjSti4h0VrLb+GeoKnOmBDemh/AnQfwTp4rpcaCuMxcTkXRVPeZ9uQjY6uOw94DRIjIcJzF8CvjvzlxXVZFQ6h2De+tBtFSl2GU8HnjpfyEiCq59MLR6LbUkaxG890fYvRQmXO92NMZ0GX8SRK2qPtLeE4vIX3HaMPqLSD5wNzBHRCbhVDEdBL7sPTYDeFxV56tqrYjcjjP2IhJ4UlW3tff69WJjYzl58iQpKSkhlyS6mqpy8uRJYmNd7NO//gk4uAKu+x0kZ7oXR3sMmQ6J6c6gOUsQpgfxJ0G8LCK3AouBhhnmVLXVHkqq6qtbyhMtHHsUmN/o9WvAR7rAdkRmZib5+fkUFRUF4nRhLzY2lsxMl27Mpw/CG3fDyMvggs+4E0NHRETA+IVOcjtbArFJbkdkTJfwJ0F81vv4zUb7FBgR+HACLzo6muHDh7sdhvF44MXbQSLg2t+GR9VSY9m5sPYR2PUaTPyU29EY0yXaTBCqandX03kbnnKqlq59EPoMbvv4UJN5ISQPdqqZLEGYHsKf6b57i8j3vT2ZEJHRInJNW58zpsHpQ/DGD2DEHJj82TYPD0kiTjfXfW9C5ek2DzemO/Bnqo2ngGpghvf1EeAnQYvIdC+qTq8lcBqmw61qqbGsXPDUwA5fvbON6X78SRAjVfUXQA2AqlYAYfy/3HSpDU/DgXfgqh9DnyFuR9M5GRdA32G20pzpMfxJENUiEofTMI2IjKRRbyZjWnTmQ3j9+zD8YpjyObej6TwRZ0zE/neg/ITb0RgTdP4kiLuBpcBgEXkOWA50fL1M0zOowktfdR6veyi8q5Yay8oFrXOWIzWmm2szQajqG0AuziR7fwVyVPXt4IZlwt77zzrLdV71I+gbxosZNZc2AVJGWTWT6RFam+57rPdxMjAUOAYcBYZ49xnj25nDsOx7MGw2TOnUXIyhR8QpRRxcCWWFbkdjTFC1Ng7i6zjTaP/ax3sKtHuyPtMDqMLLXwP1wIKHnFHI3U12Lrz7C9j+Ikz9ktvRGBM0rU33fbP38dKuC8eEvY1/hn3LYf6vnB4/3dGAcZA6zhk0ZwnCdGP+DJS7TUT6NHrd1zs3kzFNFR+BZd+FobMg5wtuRxNcWYucpVJLjrodiTFB40/5/0uqeqb+hXcFOPvZZJqqr1ry1MKC33XPqqXGsnMBhW0vuB2JMUHjz//iSGk0T7aIRAIxwQvJhKVNf4G9b8AV90C/sJjHsXP6j4aBE2BbD1jgyfRY/iSIpcDfReRyEbkcp6vr0uCGZcJKyVFY+h0YMgMu7EGFy+xFkL/O6bVlTDfkT4K4C3gL+Ip3s4Fy5hxVePkOqKvuvr2WWpKV6zxaKcJ0U/5M9+0BHvFuxjS1+W+wZxnM/TmkjHQ7mq7Vb7gzP9O2f8PMr7odjTEB19pAuX94H7eIyAfNt7ZOLCJPikihiGxttO+XIrLTe47FjXtHNfvsQe91N4nI+g58L9MVSo7B0rucJTmnftntaNyRlQtHN8Kp/W5HYkzAtVYfcIf38RrgWh9bW54G5jbb9waQrarnA7uB77Ty+UtVdZKq5vhxLdPVVOGVO6C2ChY83LOqlhrLWug8WjWT6YZa+19dP+n9T1T1UPOtrROr6rvAqWb7XlfVWu/LNUCYrFpvPuKDf8DupXD5D3pe1VJjfYY4q81ttQRhup/WEkSMiPw3MENEcptvAbj254ElLbynwOsiskFEbm7tJCJys4isF5H1RUVFAQjLtKm0AJZ8CwZPg2m3uB2N+7Jy4fgWOLHH7UiMCajWEsQtwGygDx+tXurUkqMi8j2gFniuhUNmqepkYB5wm4hc3NK5VPUxVc1R1ZzU1NTOhGX8oQqv/B/UnvVWLUW6HZH7shYCYtVMpttprRdTuqp+RUQ2qupjgbqgiNyEk2AuV1X1dYyqHvE+ForIYmAq8G6gYjCdsOV52PUaXPUTZ7CYgaQMp6F+67/hEusBbrqP1koQ9Q3IAatDEJG5OGMorvMuXerrmHgRSax/DlwFbPV1rOlipcdhyTedOveLbDquJrJzoWgHFO5wOxJjAqa1BHFSRF4HhovIS823tk4sIn8FVgNjRCRfRL4APAQkAm94u7A+6j02Q0Re8350ILBSRDYD64BXVdVGbrtNFV79OlRXwILfW9VSc+OuA4lwShHGdBOtVTF9DJgM/Anfa0K0SlVv8LH7iRaOPQrM9z7fD0xs7/VMkG39F+x8Ba78EaSe53Y0oSdxIAyd6Qyau/S73WeJVdOjtbYeRDWwRkRmqGqRiPRuqVrIdHNlhfDaN2FQDky/3e1oQld2rtOAX7AF0s93OxpjOs2f0U2jRGQ7sBNARCaKyO+DG5YJGQ1VS+Ww0KqWWjVuAUik9WYy3YY/CeIB4GrgJICqbgZa7HZquplti2HHy3DpdyB1jNvRhLb4FBhxiVPN5LuDnjFhxa/5EVS1+XzGdUGIxYSasiJ47U7ImAzT/9ftaMJDVi6cPujMz2RMmPMnQRwWkRmAiki0iNwJWF++nuC1O6Gq1Klaimxz4l8DMO4aiIh2ShHGhDl/EsQtwG3AIOAoMMn72nRn2xbD9hdgzrdhwDi3owkfcX1h5GXOUqRWzWTCnD/rQZwAbuyCWEyoKD8Br94J6ZNgxtfcjib8ZC1y1sjIfw8GT3U7GmM6rM0ShIhketduKPRu/xIRm4W1O3vtm3C2GBY+YlVLHTF2PkTG2KA5E/b8qWJ6CngJyPBuL3v3me5o+4tO/fmcu2DgeLejCU+xyTDqSqeKzuNxOxpjOsyfBJGqqk+paq13exqwaVO7o/KT8Oo3IH0izLzD7WjCW3YulB6Dw2vcjsSYDvMnQZwUkU+LSKR3+zTeMRGmm1nyLag848y1FBntdjTh7by5EBVn1UwmrPmTID4PfAIoAI4B1wOfC2ZQxgU7XoatzzvTVadlux1N+OuVAOdd5VTZeWzYkAlPbSYI7xKj16lqqqoOUNWFqvphVwRnukjFKXjl65A2AWb9n9vRdB9ZuVBeCAdXuh2JMR3SYoIQkV+KyJd97P+yiPw8uGGZLrXkLqg85e21ZFVLATP6KoiOt0FzJmy1VoK4DPC1ktwf6eSSoyaE7HwVtvwDLv6mU4IwgRPTG8bMhe0vQV2N29EY026tJYhevpYEVVUPYJPddwcVp5zpqQdOgFlfdzua7ikr1ymdHbAVc034aS1BVIrIRxYd9u6rDF5Ipsss/Q5UnHTmWoqKcTua7mnUFdAryaqZTFhqLUH8AFgiIjeJyATv9jngVe97JpztWgIf/A1mf8MWtwmm6FgYM9/pJVZb7XY0xrRLiwlCVZcAC4FLgae92xzgv1T1tZY+15iIPOmdnmNro339ROQNEdnjfezbwmc/6z1mj4h81t8vZPxQeRpevgMGZMHsO92OpvvLznWmLtn/ltuRGNMurXZzVdWtqvpZVZ3i3T6rqlvacf6ngbnN9n0bWK6qo4Hl3tdNiEg/4G5gGjAVuLulRGI6YOl3obzIqpa6yohLnek3bNCcCTN+LRjUUar6LnCq2e4FwDPe58/glFKauxp4Q1VPqepp4A0+mmhMR+xeBpv/ArO/DhmT3I6mZ4iKgbHXOj3Gas66HY0xfgtqgmjBQFU95n1eAAz0ccwgoPEqdvnefR8hIjeLyHoRWV9UVBTYSLubyjPw8tdgwHinW6vpOtmLoLoU9v7H7UiM8ZsbCaKBtxttp1ZVUdXHVDVHVXNSU20OwVYt+x6UFcKChyGql9vR9CzDL4G4fs5CTMaEiRYn+xeR39HKzVtVv9rBax4XkXRVPSYi6UChj2OO4DSI18sE3u7g9QzAnjdg05+d8Q6DJrsdTc8TGQ3jr4MP/gnVFc4gOmNCXGsliPXABiAWmAzs8W6TgM60bL4E1PdK+izwoo9jlgFXiUhfb+P0Vd59piPOFsNLX4XUsc4SosYdWblQUw57Xnc7EmP80mIJQlWfARCRrwCzVLXW+/pRYIU/JxeRv+KUBPqLSD5Oz6SfA/8QkS8Ah3BmikVEcoBbVPWLqnpKRH4MvOc91Y9UtXljt/HXsu9BWQF88s9WteSmYbMgPtUZNJe10O1ojGmTP+tJ9gWSONcbKcG7r02qekMLb13u49j1wBcbvX4SeNKf65hW7P0PbPyTswBQ5hS3o+nZIiJh/ALY+BxUlTlTghsTwvxppP45sFFEnhaRZ4D3gZ8GNywTEPVVS/3PgznfcTsaA041U20l7F7qdiTGtMmf9SCewhmwthj4NzC9vvrJhLjX/5+z7OWC3ztTPhj3DZkOienWm8mEhTYThIgIcAUwUVVfBGJEZGrQIzOds3c5vP8MTL8dBl/odjSmXkQEjF/o9Co7W+J2NMa0yp8qpt8D04H69oRS4OGgRWQ672yJMyAuZTRc+l23ozHNZedCXRXs8mtKM2Nc40+CmKaqtwFnAbxTX9gEPqHsjR9Acb4z11J0nNvRmOYyL4TkwTY3kwl5/iSIGhGJxDtoTkRSAU9QozIdt+8t2PAUTL8NBltNYEgScbq57nvTmVnXmBDlT4L4LU4D9QARuRdYCfwsqFGZjqkqdXotpYyCy77vdjSmNVmLwFMDO15xOxJjWtTmOAhVfU5ENuCMXRBgoaruCHpkpv3euBuKD8Pnl1rVUqjLmAx9hzmD5iZ/xu1ojPHJn15Mf1LVnar6sKo+pKo7RORPXRGcaYf978D6J+CiW2HIRW5HY9oi4pQi9r8D5SfdjsYYn/ypYspq/MLbHmFDckNJVRm8dDv0G2FVS+EkKxe0Dna85HYkxvjUYoIQke+ISClwvoiUiEip93UhvifYM275zz1w5rAzjbfNEho+0iY47UXbrDeTCU2trUn9M1VNBH6pqkmqmujdUlTV5m0IFQdWwHt/hGm3wNAZbkdj2kPEKUUcXOms02FMiPFnqo3veKfdnioiF9dvXRGcaUN1Obx4G/QdDpf/P7ejMR2RnQvqge1WKDehx59G6i8C7+Ksx/BD7+M9wQ3L+OU/P4Qzh7xVS/FuR2M6YsA4Z50OGzRnQpA/jdRfAy4EDqnqpcAFwJlgBmX8cHAlrPsDTP0yDJvpdjSmM7Jy4cPVUHLU7UiMacKfBHFWVc8CiEgvVd0JjAluWKZV1eXw4u1OP/or7nY7GtNZ2bmAWjWTCTn+JIh8EekDvAC8ISIv4qwEZ9yy/Mdw+gBc95BVLXUH/UfDwAlWzWRCjj+N1ItU9Yyq3gP8P+AJYGFHLygiY0RkU6OtRETuaHbMHBEpbnTMDzp6vW7n0CpY+yhc+CUYPtvtaEygZC+C/HVOd2VjQkRr4yCSvI/96jdgC85cTB1eK1FVd6nqJFWdhDPgrgJnrqfmVtQfp6o/6uj1upXqCqfXUp/BcMU9bkdjAikr13m0hYRMCGmtBPEX7+MGYL2Px0C4HNinqlZl5Y83fwKn9jtVS7aecffSbzhkXGCD5kxIaW2g3DXex+GqOqL5Y4Cu/yngry28N11ENovIEhHJauEYRORmEVkvIuuLiooCFFYI+nANrPk95HwBRlzidjQmGLIWwdGNzo8AY0KAP+Mglvuzr71EJAa4Dvinj7ffB4aq6kTgdzgN5D6p6mOqmqOqOampqZ0NKzTVVMILtzqLzFz5Q7ejMcGStch5tGomEyJaa4OI9bY79PeOpK5vixgGDArAtecB76vq8eZvqGqJqpZ5n78GRItI/wBcMzy9+RM4tQ8W/A56JbodjQmWPkOc1eYsQZgQ0VoJ4ss47Q1jvY/124vAQwG49g20UL0kImkiIt7nU71x9sw5kT9cC6sfhimfgxFz3I7GBFtWLhRsgRN73Y7EmFbbIB5U1eHAnY3aHoar6kRV7VSCEJF44Erg34323SIit3hfXg9sFZHNOCvafUpVtTPXDEs1lU6vpeRMuNI6cvUIWQsBscZqExL8WVHudyIyAxjW+HhVfbajF1XVciCl2b5HGz1/iMCUUsLbWz+Fk3vgM4shNsntaExXSMqAIdOdQXOXfMvtaEwP59eKcsCvgFk4czJdCOQEOS5z+D1Y/RBM/iyMvMztaExXys6Foh1QaCv7Gne1WYLASQbje2QVj1tqzsKLt0JiBlz1E7ejMV1t3HWw5FtOKeKy77kdjenB/JmLaSuQFuxATCNv/wxO7IbrHrSqpZ4ocSAMnem0Q9jvMuMifxJEf2C7iCwTkZfqt2AH1mPlb4BVv4ULPgOjrnA7GuOW7Fw4uReOb3U7EtOD+VPFdE+wgzBeDVVL6XD1vW5HY9w0bgG8eqdTzZQ2we1oTA/lz2yu7wAHgWjv8/dwRjqbQHvnPijaCdc+CLHJbkdj3BSf4kypYtVMxkX+9GL6EvA88AfvrkG0MvWF6aAj70PegzDp0zD6SrejMaEgKxdOH3TmZzLGBf60QdwGzARKAFR1DzAgmEH1OLVVzoC4hAFWtWTOGXcNRETboDnjGn8SRJWqVte/EJEowMq8gfTuL6Fwu1O1FNfH7WhMqIjrCyMvhW0vWDWTcYU/CeIdEfkuECciV+LMvvpycMPqQY5ughX3w8T/hvOudjsaE2qycqH4MOS/53YkpgfyJ0F8GyjCWU3uy8BrwPeDGVSPUVvtTOMdnwpzf+p2NCYUjZ0PkTE2w6txhT9zMXmAP3o3E0grfgWF2+CGvznVCcY0F5sMo650qpmuuhci/PlNZ0xg+NOLaaaIvCEiu0Vkv4gcEBFb8qqzjm2GFb+G8z8FY+a5HY0JZdm5UHoUDq9xOxLTw/gzUO4J4P9w1oKoC244PURtNbxwG/ROgbk/czsaE+rOmwtRsc6guaEz3I7G9CD+lFeLVXWJqhaq6sn6LeiRdWcr74fjW+CaB6B3P7ejMaGuVwKMvgq2vwge+41muo4/CeItEfmliEwXkcn1W9Aj664KtjjdWid8wmmANMYf2blQXggHV7odielB/KlimuZ9bLwGhAK2SEF71dXAC1+BuH4w7z63ozHhZPTVEB3vDJobcYnb0Zgewp9eTJcG48IichAoxWnXqFXVnGbvC/AgMB+oAG5S1fCeA2rlb5wSxCefs6ol0z4xvWHMXNj+Esz/NUT689vOmM7xpxdTsojcLyLrvduvRSRQM8ldqqqTmicHr3nAaO92M/BIgK7pjoKt8M4vIPt6ZwoFY9orKxcqT8GBd9yOxPQQ/rRBPInzS/8T3q0EeCqYQXktAJ5Vxxqgj4ikd8F1A6+uxpnGO64PzPuF29GYcDXqCuiVZHMzmS7jT4IYqap3q+p+7/ZDYEQArq3A6yKyQURu9vH+IOBwo9f53n1NiMjN9aWboqKiAIQVBHkPOOMePna/M42zMR0RHQtj5sOOl52u0sYEmT8JolJEZtW/EJGZQGUArj1LVSfjVCXdJiIXd+QkqvqYquaoak5qamoAwgqw49vh7fuc6oHx17kdjQl3WYvgbDHsf8vtSEwP4E+C+ArwsIgcFJFDwEM4czJ1iqoe8T4WAouBqc0OOQIMbvQ607svfNTVOr2WYpNh/i/djsZ0ByMvc/49bbVqJhN8/qwot0lVJwLnAxNU9QJV/aAzFxWReBFJrH8OXAU0X3z3JeB/xHERzoC9Y525bktqPbXBOC2sehCObYKP/Rri+wfnGqZniYqBsdfCzledJWqNCaI2+8qJSApwNzALUBFZCfyok6OpBwKLnZ6sRAF/UdWlInILgKo+ijNr7HxgL04318914notUlWuWXwNgxIGMSNjBjMHzWRM3zF4Y+u4wh3w9s9h/ELIWhiIUI1xZC+CTX+Gfcth7MfcjsZ0Y6JtLEQiIm8A7wJ/9u66EZijqlcEObZ2y8nJ0fXr17frM2drz/L7Tb8n72geu0/vBiAlNoWZg2YyI2MG0zOm0y+2nWMW6mrhiSvhzCG4dS0khGDbiAlfdTXwq/Oc6qbrn3A7GhPmRGRDC0MN/EoQW1U1u9m+Lao6IYAxBkRHEkRjhRWFrDq6ilVHVrH62GrOVJ1BEMaljGNmxkxmDprJ+annEx0R3fqJVv4G/nMPXP+UM0WCMYH28tfgg3/CN/c6g+iM6aDOJoj7gXXAP7y7rgemquqdAY0yADqbIBqr89Sx49QOVh5Zyaqjq/ig6APqtI6E6ASmpk1tKGFkJmY2/WDhTvjDbGcGzk88C52tqjLGl/3vwLPXwcefsSpM0ymdTRClQDznpvqOBMq9z1VVkwIVaGcFMkE0V1Jdwrpj68g7mkfekTyOlTvt5cOShjW0XeSkXkDvZxfAqQNw21pIGBCUWIyhrhbuH+tM//2JZ92OxoSx1hKEP3MxJQY+pPCTFJPEFUOv4IqhV6CqHCg5wKojq8g7mse/9/ybv+z8C9FEMLmugplTFjKj+jTnaWrnG7uN8SUyCsYvgI3PQVWZMyW4MQHmTwniC6r6RKPXkcD3vSOqQ0owSxCtqaqrYsOul1i1/C7yklPYq073w9S41IbSxfT06fSJ7dPlsZlu7GAePD0f/usJmHC929GYMNWpEgRwuYj8F/AFIAVnHiabLayRXhLFjFV/YEaFhztveoWCCGX10dXkHc3jrcNv8eK+FxGErJQsZgyawaxBs5jQfwJRETYjp+mEIdMhMR22LbYEYYLCnyqm/xaRTwJbcNoe/ltV84IeWThZ83vIfw9yH4fEgaQBi0YvYtHoRdR56th2cltD28XjWx7nsQ8eIzE6kWnp05gxaAYzM2aSkZDh9rcw4SYiwhlns/5JOFsCsSHTHGi6CX+qmEYDz+AkiHHAduDrqloR/PDax5UqphN74NFZMPJy+NRzbfZaKq4qZu2xtaw6uoqVR1ZyvOI4AMOThzMzw+kZlZOWQ1xUXFdEb8Ld4XXOmJtFf4CJn3I7GhOGOtuLaSdwm6ou9y7i83Xg86qaFfhQO6fLE4SnDp6aB0W7nF5LiWnt+riqsr94P3lH8lh1dBXrj6+nqq6KmIgYpgyc0tCVdlSfUdbYbXxThQcmwIDxcOM/2j7emGY62wYxVVVLwOnTCvxaRF4OZIBha+2jcHgtLHqs3ckBQEQY2WckI/uM5H+y/oeztWfZcHwDeUfzWHVkFb9a/ysABvQe4JQuBs1gevp0knsFar0mE/ZEnN5Ma/8Alachrq/bEZlupMUShIh8S1V/4X3+cVX9Z6P3fqqq3+2iGP3WpSWIk/vgkRkw4lK44a9BGRBXUF5A3pE88o7msebYGkqrS4mQCLJTshtKF9n9s62xu6c7sgH+eBlc9xBM/ozb0Zgw06EqJhF537teQ5Pnvl6Hii5LEJ46eGo+FO1w5lpKCv5Cd7WeWrae2NpQuthyYguKkhiTyEXpFzFr0CxmZMwgLb79JRkT5lTht5Og3wj4zGK3ozFhpqNVTNLCc1+ve5Z1j8HhNbDw0S5JDgBREVFMGjCJSQMmcduk2yiuKmb1sdVO+8WRVbxx6A0ARiaPbOgZNWXgFGKjYrskPuMiEWchobzfQvlJW7XQBExrCUJbeO7rdc9xch/854cw+mpXe40k90pm7rC5zB02F1Vl75m9DT2j/r7z7/xp+5/oFdmLnIE5DYP1RiSPsMbu7ior15kkcsdLkBOUmfFND9RaFVMdzrgHAeJw1mTA+zpWVduY0rTrBb2KyeOBpz8Gx7fBbWsgKTTHLlTWVrK+YD2rjjpTgRwoPgBAWnxaQ1faaenTrLG7O1GFh3Kcf5OftT4kxn8dqmJS1cjghRSm3vsjfLgKFvw+ZJMDQFxUHLMzZzM7czYAR8uONrRdLDu4jH/t+RcREsGE/hOYOWgmMzNmkpWSRWSE/ZWHLRGnFLHiV1BWaBNFmoBocxxEOAlqCeLUfnhkJgydCTf+M2yn8a711LLlxBZnGvMjq9h2chuKktwrmYvSL2ooYQyMH+h2qKa9jm+HR6bD/F/B1C+5HY0JE50aKBdOgpYgPB545loo+ABuXQPJgwJ/DZecPnuaNcfWNKx7caLyBACj+oxqWCRp8sDJ9Irs5XKkxi8PT4O4fvD5JW5HYsJEZwfKBTqYwcCzOOtSK/CYqj7Y7Jg5wIvAAe+uf6vqj7owzKbWPwGHVjr9zLtRcgDoG9uXecPnMW/4PFSV3ad3O20XR/L4y86/8Mz2Z4iNjCUnLadhsN7wpOHW2B2qsnLh7Z9BydGQrgY14aHLSxAikg6kq+r7IpIIbAAWqur2RsfMAe5U1Wvac+6glCBOHXCqloZcBJ/+V9hWLXVERU0F64+vb5gK5GDJQQAy4jMautJOS59GYowtGRIyTuxxGqvn/hwu+orb0ZgwEFIlCFU9BhzzPi8VkR3AIJxJAEOLxwMv/S9IBFz32x6VHAB6R/fm4syLuTjzYgDyS/MbShdLDizh+d3PEymRTEyd2NCVdnzKeCIkouEcqkpNnVJd56G61kON97Gq0fPqOg81tR6qvI++j1XvsXUNz5uco/55XQv7az0ATBuRwtzsNC45L5XY6G7YKN9/NAycAFv/bQnCdJqrbRAiMgx4F8iun+/Ju38O8C8gHziKU5rY1sI5bgZuBhgyZMiUQ4cOBS7A9x6HV78B1/4Wpnw2cOcNAo9HW7w5VjW6CTe++VY1HKNU19Y5x9Rpo/3NztPks9UUe/ZSKtsoj9xOTdSHTiB18cjZ0XjKx1BdOprq6sCudBYZIURHCjGREcRERRITKcRERRATFUF0pPMY0+yxfn9VrYd3dxdRXFlD75hILh0zgLnZaVw6dgAJvbrRdCUrfg3LfwR3bIU+g92OxoS4kGykFpEEnIWH7lXVfzd7LwnwqGqZiMwHHlTV0W2dM6BVTKcPwe+nw+CpzvQFIqgqtR71ffNtdDOtbnJjVarr6rz79SO/aqubPdb4vIE3ft/Hr+c6D3WewP49xkRGODdiP2++RJZRKts4o1s5UbeFKi0GoG/UUIbEXcDw+AsYGp9NXHSvFs/R/PzRPq4XGdG5UlxNnYc1+0+yZGsBr28r4ERZNTFREVw8OpV52WlcMW4gyb1DbohP+5zaD7+9AK78Mcz8qtvRmBAXcglCRKKBV4Blqnq/H8cfBHJU9URrx3U0Qdz01DrKq2rP3cBravlFxf9jrGcvH4+4n8N1KU71R52HQP5xRQgNN8hePm6K9TfOXvXPP3LT9P8G/pGbb/NzN5zH+XXemUZoj3rYfXp3Q8+ojYUbqfXUEhcVx4VpFzrVURkzGZo01NXG7jqPsv7gKZZsLWDZtgKOFZ8lKkKYMao/87LTuGr8QFISwrT31h8ucapEb37b7UhMiAupBOFdU+IZ4JSq3tHCMWnAcVVVEZkKPA8M1TaC7WiC+PTja6nzaMPN9/LyV7ih8Df8K+NONg5YeO5mGtn8ZvrRG7jP/Y1uvr0iIxueR0VGtB1cN1BeU857Be81zEx7uPQwAIMSBjX0jJqWNo2EmMBWR7WHx6Nszj/D0q0FLNlawIenKogQuHBYP+ZlpzE3O5205DCa1yrvQXjjB/DVjc4kfsa0INQSxCxgBc4KdR7v7u8CQwBU9VERuR34ClALVOKsYLeqrXMHpIrpzIdO1VJmDnzmhR7XMN0VDpccdpZgPZrH2mNrqaytJEqimDhgYkPCGNdvXJPG7q6kqmw/VtKQLPYWlgFwwZA+zMtOY152OoP79XYltpZU1FRwvOK4s5Ufp/DUbo6vfZiyjIlMzr6RWYNm2bK2xqeQShDB1OkEoQp/Wgj56+Erq6Dv0IDFZnyrqathU9Gmhq60O07tAKBfbD+mZ0xnZsZMpmdMp39cf9di3FtY2pAsth11+lJkZSQ1lCxGDQheyUdVKasp43j58SYJ4HjFcQoqChqel1aXfuSzfVSIBorE+T9ev6zt7EGzmZI2xQY/GsAShP82PA0vfw0+dj9c+IWAxWX8d6LyBKuPribvaB6rj67m1NlTAIztN5YZGTOYNWgWk1InER3pTkPyhycrWLrtGEu2FrDxwzMAjB6Q0JAsxqUn+t2uoqqcqTrT9KZfXkBhRWGTZFBR+9Hl31NiUxgYP5CBvb2b93lafBoDew9kQO8BxK5/Cl36bQ6kZ5GXNoqVETWsP7Obak91w+DHWYNmMWvQLIYkDrHBjz2UJQh/nDnsVC0NugA+8yJE9Iz2gVDmUQ87T+1smMZ8c+FmarWW3lG9mZo2lRmDZjArYxaDk9zpynmsuJJl3pLFewdP4VEYmtKbudlpXJ01kMH96yisKGzyS79xMjhefpxqT3WTc0ZIBKlxqU1u/vU3/YHxzo1/QNwA/xJkXY2zLO7OV52lcdVDZUIa64dPYWV8InkVhznkbQ/KTMhsSBYXpl1I7+jQqkLzl6rTTbtbjnFprqoUDqyAfcuhvAg+8WyHTmMJoi2q8Odc+HAt3LoK+g4LeGym88qqy1hXsK4hYRwpOwLA4MTBDT2jpqZPJT46Pqhx1HpqOVF5goLygoYb/aHiY2wp+JAPS45SWnsSiSpGxNPkc1ERUed+8Tf61d84GaTEpQRnCdnyk7D3Ddi1BPa9CVUlEBXL4WHTyUsdwkqtYN3JD6isrSQ6IpopA6cwa9AsZmbMZGSfkSFZuig9W8Pu46XsLChl57FSdhaUsLOglLKqWkalJnB+Zh8mDU7m/Mw+jE1PpFdUmCcNj8eZD27fctj7ppP0PTUQHQ8jLoFP/Aki2/9vxxJEW95/1hkxbbNghg1V5cPSDxvaLtYVrHMauyOiuGDABQ0JY0y/Me1q7K6uqz5XxdPCr/4TZ0/g0aY3/9jI2IYbfd9eqZSXJ5B/Ipo9RyOprkqkb8wArh47gvkTBjFtRD+i3ezBVlvtTFu/aynsXgKnDwJQnTaB94dOZmVsL/KK97C3eB9wbh2RWYNmuTK1Sp1HOXiynJ3HStlVUMKOAicZHD5V2XBMQq8oxqYlMjY9kb69Y9h2tITNh89wstwpocVERjAuPZHzM/swcXAfJmYmMyI1odPjaoKurNBJ6HuXw/63nJICQNoEGHk5jLocBk+DqI63J1mCaE3laXjgfEifCP/zklUthanqumo2Fm5sWPdi1+ldgNPYXT8NSM7AHM7Wnm246RdWFDYpBRyvON7Q5tFY76jeTap5mv/qT4tPIykmyeev7LKqWt7cWcjSrcd4a2cRlTV19OkdzZXjBjJvQhozR/V395etKhTtgt1Lnc1bFUVCGgWjLmZlvwzyak6x5vh6ymrKGnqb1Zcu2puA23KqvJqdx5wksMtbIthVUEqVd6qUCIERqQmMSUtkXFoiY9OSGJueyKA+cR/581dVjpyp5IP8YjYfPsPm/DNsyS+mvLoOgPiYSCZkJjMxs483cST7PE+Xqq12/g72LXeSQsEHzv7eKTDyMicpjLwMEgM3Hb8liLbsWgqpY6Df8MAHZVxRVFHUsKLe6qOrOVN1xudxyb2SP1rl0+x5oMZnVFbX8c7uIpZuPcbyHYWUVtWS2CuKy8YNYF52GpecN4C4GJerQVqoiqoZdjEfZE5gZa8I8k580NDbLCU2hZmDnNLF9PTp9Int49dlqmrr2FdY3lAttONYCbsKSiksrWo4JiU+hnHpSYxNS3QSQnoSowYkdKp9oc6j7C8qY3N+MR/kn2Hz4TPsOFZKdZ2n4ZrnZyZ7Sxl9OD8zOfiDJU/uO1dKOLgCqssgIsopGYy8zCklpE0M2o9XSxCmR/Oohx0nd7CpaBNJMUlNGnzjouJciamqto5Ve0+ydGsBr28v4HRFDXHRkcwZk8rc7DQuGzuAxFiXp/xooSqKtPM5MWoOecmp5FUcZtWx1RRXFRMhEWT3z2ZWxixmDnJWKYyQCI4Vn2VXQSk7Ckoa2gr2F5VT650eJiYygtEDExiblsS4dCcZjE1LIjWxa7rhVtXWsfNYqZMwvKWNvUVlDbMmZPaNY6K3hHF+Zh8mDEomvjNzd1WVwoF3nYSwb/m5P9e+w85VGw2bDbFJnf1qfrEEYUwIq63zsO6AM+XH0m0FFJVWERMZwazR/ZnrnfKjT+8Yd4NspSqqbvSVbM3I4i09y9tH1rCvZAegRGo8deXnUVkyirqy89A6pyqovq2gPiEMS4kPuVkFyqpq2XrESRYf5BezOf8M+aedNo8IgVEDEpq0Z4xNS3LmJPPF44GCzd6EUN+4XOs0Lg+/2EkIIy+DlJFd+A3PsQRhTJjweJT3PzztJIutBRw5U0lkhDB9RArzJqRx1fi0Lvtl3ZI6j5J/5DBnNr9G3IE3GHx6NXGecs5qNHmebJaQxarEPkhKIWejt1Ptnaj5vL5juSRzNjMHzWRi6sTg9NYKopNlVQ3Joj5xNGkEz0hiordNY3JKNUPPrCVi35tOUqjwTiPXpHH5IohyOfFjCcKYsKSqbDlS3JAsDpwoR7zzQ83NSmNudhoZfYJbRXa6vNrpRlpQ4q0mKmV3QSmVNU5Db4TAqJQYrkk+yGzdwJjilfQud8ZWkHY+nvPmsjN9HHnVJ1h5NI/NRZup0zoSoxO5KOOihmVt0+LTgvo9gqG+EXzz4WK2flhE1YFVZJxYxXTdRFaEs+xAcUQyh/teRO3wyxh4wTzSMkJvQKIlCGPCnKqy63gpS7Y4yWLXcWdqjYmD6+eHSmNoSsfHf1TXeth/ooydx5y2gl3esQUFJWcbjukXH+NUD3l7Do1NS2T0gMSmDeutVEVx3lWUjJjD2rhe5B1fz4ojKyisKAScNdBnDXLaLiYPmExMpPu/rFul6kyrXt+OcGAF1JSjEVFUpuWwL2kaKzwTef1kKtsKyqipc+6z/RNiGnpNnT/YKW30i3f3u1qCMKab2V9U1lCy2HLEWXtjXHpSQ7IYPdD3WAVVpbC0ih3HSrwDzJzHfUXnbmIxkRGMHJDgdCNNP5cQUhN6tf/Xb32vqN1LnZupt1cUwy9BR1/F3vRx5BXvYeXRlWw4vqFhWvhpadMaekdlJmZ26s8qYM6WOI3L9V1Qz3gXJ2ujcblxI/imw07vqcaN4IP7xTmD+ry9prK9jeCqSmVtJSXVJRRXFTc8Nnle7byOiYzh57N/3qGvZQnCmG7s8KkKlm1zpvzYcOg0ACNT45mXnc70kSnkn65gx7Fz1USnK2oaPpuRHOv0GvJ2Jx2XnsTw/vHBGcjXSq8oxsyjYsQc1nGWlceajpQfljSMmYNmMjNjJhemXUhsVBdNux6gxuU6Tx2l1aVNburHy06zq/A4+08Vkl98ksLy01TWlUFkBRGRlURFV6IRlSi1LZ43KiKK5Jhkknslkx6fzqNXPtqhr2kJwpge4njJWSdZbClg7YGT1C802DsmsqH7qFNN5Dx3bfW8NqqidPRcDqWOJK9oAyuPrOS9gveoqquiV2QvcgbmNJQuhiUNC2ydfulxJxnsWw773mrUuHw+Z0fOoWTwVIr7j6S4tuIjv+wb/8Ivri6mpKqE4upinzPtNtY7qjfJvZKJj0okQuOpro6lrDKaUyVRVJ7thXriiCSeoX36M3bAQCamZ3Dh0EGMH9ifyAAkcksQxvRAJ8uq2Hq0hGEpvRnctzcRoTytRCtVUZx3NWdHXsqGymOsPLKSlUdWcrDkIHBu0amZg2YyLX1am/NwedRDWU2Zc0OvKqG48gQlRzdQfOx9Sop2UlxZRHFEBMXRsZT07ktxTCwleCiuKaOqrqrF80ZIRMOv+aSYJJJ6JZHcK5nkmGTnufe9Ju9734uO8J2kVZX8085IcKd66gxbj5wbCZ7YK4rsQckNXW2vzkrr0N+xJQhjTPhooyqK8+aSn9CfVQVrWHFkxblFpyKimDxgMtn9s6moqXB+xVeXOInA+6u+tLr0I/NoNRYnUSTGJJIc17/JDd3Xzb3xvvjo+C5Z4KrOo+wrKmsyPmPHsRL6xcew9rtXdOicliCMMeGpjaoozptHzdCZbDyzi5VHndLFvjP7SIhOOPcLPro3ydVnSSo/RfKZfJIqTpPs8ZAcl0ryoCkkDZlF8ohLSUrMCMtFlKpq6zh25izD+nesF1vIJQgRmQs8CEQCj6vqz5u93wt4FpgCnAQ+qaoH2zqvJQhjurk2qqI4by6akIYUbD43LXb+OqdxOSbBaVyun9/I1uoGQixBiEgksBu4EsgH3gNuUNXtjY65FThfVW8RkU8Bi1T1k22d2xKEMT1IS1VRvZKcxAHOLM31XVAzp4bEyOVQ01qCcGOs+1Rgr6ruBxCRvwELgO2NjlkA3ON9/jzwkIiIdqf6MGNM50TFwIg5zjb3Z3BitzML7an9MHQmjLwUEga4HWVYcyNBDAION3qdD0xr6RhVrRWRYiAFONH8ZCJyM3AzwJAhQ4IRrzEm1Ik4U/anjnE7km4ltKZQ7ABVfUxVc1Q1JzU11e1wjDGm23AjQRwBGq8yn+nd5/MYEYkCknEaq40xxnQRNxLEe8BoERkuIjHAp4CXmh3zEvBZ7/PrgTet/cEYY7pWl7dBeNsUbgeW4XRzfVJVt4nIj4D1qvoS8ATwJxHZC5zCSSLGGGO6kCsrdqjqa8Brzfb9oNHzs8DHuzouY4wx54R9I7UxxpjgsARhjDHGJ0sQxhhjfOpWk/WJSBFwqIMf74+PgXjdnH3n7q+nfV+w79xeQ1XV5yCybpUgOkNE1rc0H0l3Zd+5++tp3xfsOweSVTEZY4zxyRKEMcYYnyxBnPOY2wG4wL5z99fTvi/Ydw4Ya4Mwxhjjk5UgjDHG+GQJwhhjjE89PkGIyJMiUigiW92OpSuIyGAReUtEtovINhH5mtsxBZuIxIrIOhHZ7P3OP3Q7pq4iIpEislFEXnE7lq4gIgdFZIuIbBKRHrH+sIj0EZHnRWSniOwQkekBO3dPb4MQkYuBMuBZVc12O55gE5F0IF1V3xeRRGADsLDxmuDdjYgIEK+qZSISDawEvqaqa1wOLehE5OtADpCkqte4HU+wichBIEdVe8xAORF5Blihqo97l1DorapnAnHuHl+CUNV3caYU7xFU9Ziqvu99XgrswFnitdtSR5n3ZbR36/a/jEQkE/gY8LjbsZjgEJFk4GKcJRJQ1epAJQewBNGjicgw4AJgrcuhBJ23qmUTUAi8oard/jsDDwDfAjwux9GVFHhdRDZ416vv7oYDRcBT3qrEx0UkPlAntwTRQ4lIAvAv4A5VLXE7nmBT1TpVnYSzxO1UEenW1Ykicg1QqKob3I6li81S1cnAPOA2bxVydxYFTAYeUdULgHLg24E6uSWIHshbD/8v4DlV/bfb8XQlb/H7LWCuy6EE20zgOm+d/N+Ay0Tkz+6GFHyqesT7WAgsBqa6G1HQ5QP5jUrEz+MkjICwBNHDeBtsnwB2qOr9bsfTFUQkVUT6eJ/HAVcCO10NKshU9Tuqmqmqw3CW7H1TVT/tclhBJSLx3o4XeKtZrgK6de9EVS0ADovIGO+uy4GAdThxZcnRUCIifwXmAP1FJB+4W1WfcDeqoJoJfAbY4q2TB/iudxnY7iodeEZEInF+FP1DVXtEt88eZiCw2PkNRBTwF1Vd6m5IXeJ/gee8PZj2A58L1Il7fDdXY4wxvlkVkzHGGJ8sQRhjjPHJEoQxxhifLEEYY4zxyRKEMcYYnyxBGNNOIvI976ywH3hnDZ0mIneISG+3YzMmkKybqzHt4J1K+X5gjqpWiUh/IAZYRQ+bRdR0f1aCMKZ90oETqloF4E0I1wMZwFsi8haAiDwiIuubrz8hIvO98/ZvEJHf1q/T4B0F/KR33YqNIrKg67+aMU1ZCcKYdvBOcrgS6A38B/i7qr7TfB0CEemnqqe8o7eXA18FdgN7gItV9YB3FH+iql4jIj8Ftqvqn73TgqwDLlDV8q7+jsbUsxKEMe3gXVdiCnAzzjTLfxeRm3wc+gkReR/YCGQB44GxwH5VPeA95q+Njr8K+LZ3+pO3gVhgSBC+gjF+6/FzMRnTXqpah3MTf1tEtgCfbfy+iAwH7gQuVNXTIvI0zg2/NQL8l6ruCnzExnSMlSCMaQcRGSMioxvtmgQcAkqBRO++JJx5+YtFZCDO2gQAu4AR3oWaAD7Z6DzLgP/1zraLiFwQlC9gTDtYCcKY9kkAfudtJ6gF9uJUN90ALBWRo6p6qYhsxJlS/DCQB6CqlSJyq/e4cuC9Ruf9Mc4KcB+ISARwAOj2a0ib0GaN1MZ0IRFJUNUyb0nhYWCPqv7G7biM8cWqmIzpWl/yNkRvA5KBP7gbjjEtsxKEMcYYn6wEYYwxxidLEMYYY3yyBGGMMcYnSxDGGGN8sgRhjDHGp/8PPrw3/n6QCP0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#re-convert rounds to their respective integers for plotting, too lazy to use actual Datetime kappa\n",
    "newton[\"Round\"] = newton[\"Round\"].map(interested_rds)\n",
    "\n",
    "print(newton)\n",
    "\n",
    "plotted_stg = [\"Q_RC1\", \"Q_LN1\", \"Q_HB1\"]\n",
    "for stage in plotted_stg:\n",
    "    x, y = newton[\"Round\"], newton[f\"{stage}\"]\n",
    "    plt.plot(x, y, label = f\"{stage}\")\n",
    "    \n",
    "plt.xlabel(\"Stage\")\n",
    "plt.ylabel(\"Exponentiated Coefficients\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "This is actually an interesting result to behold. There are a couple of reasons why this is pretty unexpected:\n",
    "- Stage 3 (Q_LN1) is an LN map that tests both versatility in early-game and mid-game density patterns; it's high significance from RO16 to QF makes lots of sense, and is validated by the model as well. Its slow increase in later rounds is slightly interesting, but a future topic for discussion.\n",
    "\n",
    "- Stage 2 does, in fact, play a huge significance in earlier rounds (highest parameter in RO16 / round int 1). It is after all meant to be the accuracy qualifier; If you had good accuracy and MA ratio on Stage 2, this would have directly translated into a good result in the earlier rounds, such as RO16 (this could have been even higher in RO32).\n",
    "\n",
    "- However, it is also pretty unexpected that Stage 2's significance in determining if a team wins the tournament is also in the 10s. It is generally expected that the set of parameters gradually decrease as the round integers increase, since qualifiers are designated to only test skillsets in the early-midgame, and play a much smaller significance at later rounds where high scores/ratios take the backseat for consistency and combo skill.\n",
    "\n",
    "- In fact, Stage 4 (Q_RC2) was expected to be the stage with the highest parameter going into the later rounds. It does peak in significance at QF, which makes some sense since the midgame pools were designated in a way to differentiate teams with players of sufficient endurance levels with decent accuracy.\n",
    "\n",
    "- On the end of Stage 5 (Q_HB1), it was expected to peak in significance and represent a difficulty between QF and SF. This does seem to be represented in the predicted model parameters, as the parameter value increases from QF to SF, and maintains a stable decrease in value over SF to GF. \n",
    "\n",
    "- It is, of course, slightly perplexing that the parameter of Stage 5 on RO16 seemed to match that of Stage 2. This stage is not accuracy-oriented, or mapped in a way for it to be accuracy-friendly. Perhaps it is because the teams who did well on this Stage also had very strong base accuracy, but this is something that could be debatable upon reconcillation with the statistics sheet from 4DM4.\n",
    "\n",
    "### Conclusions\n",
    "There are general trends that the logistic regression model with the Newton solver seemed to get right, especially the significance of the stages tallying up well with its intended difficulty initially declared by the charters.\n",
    "\n",
    "However, some fluctuations towards the later rounds were large, but not unexpected; with much lesser matches happening following each of the later stages, it is pretty difficult for the model to fit with the bigger picture. This could also mean that teams that made it to later rounds would singlehandedly spike/drop the significance of specific stages just based on the qualifier stages they did exceptionally well in. These are unfortunately limitations with the data that can be generated while in the context of a tournament; few matches at the later stages are bound to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "As aforementioned, the limited amount of data pertaining to team-based tournaments (and specifically 4DM4) limits the effectiveness of the model as we advance on into later rounds.\n",
    "\n",
    "- It may be possible to tackle this with dummy data or by collecting more data from possible showmatches between 4DM4 players using each of the pools. On the other hand, a tournament condition for the human is difficult to replicate in a normal practice session (including the presence of nerves, and technical issues), which inherently still poses a problem to data that we could possibly collect to improve the predictions of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential areas of development\n",
    "\n",
    "This data analysis could be scaled up to no-rank limit tournaments, to expand on the player pool and thus number of scores we could possibly obtain for running the same analysis. Qualifier pools could be compared against one another on the same scale, and grouped into specific difficulty levels and skillsets.\n",
    "\n",
    "### Thoughts\n",
    "\n",
    "I hope it was interesting to see me (lowkey) suffer on this analysis. It was really a day's worth of code, with 2-3 days of puzzling about the results with HTPLN. \n",
    "\n",
    "If this analysis interests you and you are interested to know how your tournament mappools/operations could benefit from statistical analysis, contact me or HowToPlayLN on Discord for more details :))))\n",
    "\n",
    "-Poly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
